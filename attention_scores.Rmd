---
title: "Example analysis of Rayan's project"
output: html_notebook
---


Read in the data

```{r}
library(dplyr)
library(data.table)
library(tidyr)
library(stringr)
library(DescTools)
library(ggplot2)
library(dplyr)
library(stats)
library(readr)



# a <- fread("~/Downloads/gwas_catalog_v1.0.2.1-studies_r2024-03-11.tsv")

a <- fread("/Users/rayanaloliet/Desktop/GWAS Catalog/gwas_catalog_v1.0.2.1-studies_r2024-06-07.csv")

```



Have a look at the data

```{r}
hist(a$`ASSOCIATION COUNT`, breaks=100)
```

Sometimes there is more than one EFO term (comma separated). Split them into separate lines

```{r}

head(a, 10)

a <- a %>%
    tidyr::separate_rows(MAPPED_TRAIT_URI, sep = ", ")

head(a, 10)

```

Get the number of EFO terms per publication

```{r}
pubmed_count <- a %>% group_by(PUBMEDID) %>% 
    summarise(
        n_efo = length(unique(MAPPED_TRAIT_URI))
    ) %>% arrange(desc(n_efo))

pubmed_count
```

Add the EFO count per PUBMEDID to the data frame

```{r}
a <- left_join(a, pubmed_count, by="PUBMEDID")
str(a)
```

Step 1. Develop the attention scores

- n = number of studies with that EFO term
- weighted_n = weighted by number of EFO terms in the study in total
- nhits = number of GWAS hits reported for that EFO term
- weighted_nhits = nhits weighted by number of EFO terms in the study in total

```{r}
attention <- a %>% group_by(
    MAPPED_TRAIT_URI
) %>% 
    summarise(
        n = n(), 
        weighted_n = sum(1/n_efo),
        nhits = sum(`ASSOCIATION COUNT`),
        weighted_nhits = sum(`ASSOCIATION COUNT` / n_efo)
    )

str(attention)
```


Removing extra whitespace, cleaning the Impact factor values and ensure the values are numeric 

```{r}
# Remove extra whitespace
a$`Impact factor` <- trimws(a$`Impact factor`)

# Replace non-standard characters
a$`Impact factor` <- gsub("Â·", ".", a$`Impact factor`)

# Convert to numeric, forcing non-numeric values to NA (for those with no impact factors)
a$`Impact factor` <- as.numeric(a$`Impact factor`)

# Replace NA values with 0
a$`Impact factor`[is.na(a$`Impact factor`)] <- 0

# Verify the changes
str(a)
unique(a$`Impact factor`)
summary(a$`Impact factor`)


```
 Including the impact factor values after preparing and cleaning to the attention scores
 
```{r}

# Including the impact factor and (`DISEASE/TRAIT`) column for partial matching 

attention <- a %>% 
  group_by(MAPPED_TRAIT_URI) %>% 
  summarise(
    n = n(), 
    weighted_n = sum(1 / n_efo),
    nhits = sum(`ASSOCIATION COUNT`),
    weighted_nhits = sum(`ASSOCIATION COUNT` / n_efo),
    weighted_attention_score_impact_factor = sum((1 / n_efo) * `Impact factor`, na.rm = TRUE),
    DISEASE_TRAIT = first(`DISEASE/TRAIT`)
  )



str(attention)
str(a)
head(a)
```
 
Step 2. Merging the GWAS attention scores with the GBD disease burden results

```{r}

gbd_data <- fread("/Users/rayanaloliet/Desktop/GWAS Catalog/GBD.csv")
str(gbd_data)

  # unique matched rows  by GBD term
gbd_data <- gbd_data %>%
  distinct(`GBD term`, .keep_all = TRUE)


```

Specify columns that contain EFO terms

```{r}

efo_columns <- c("EFO 1", "EFO 2", "EFO 3", "EFO 4", "EFO 5", "EFO 6", 
                 "EFO 7", "EFO 8", "EFO 9", "EFO 10", "EFO 11", "EFO 12",
                 "EFO 13", "EFO 14", "EFO 15", "EFO 16", "EFO 17", "EFO 18",
                 "EFO 19", "EFO 20", "EFO 21", "EFO 22", "EFO 23", "EFO 24",
                 "EFO 25", "EFO 26", "EFO 27", "EFO 28", "EFO 29", "EFO 30")
```


Reshape the GBD data to gather all relevant columns into key-value pairs and drop rows with NA EFO terms

```{r}

 gbd_long <- gbd_data %>%
pivot_longer(cols = all_of(efo_columns), names_to = "EFO_number", values_to =  "MAPPED_TRAIT_URI") %>% drop_na(MAPPED_TRAIT_URI) 

gbd_long
```

Separate rows based on a separator (assuming comma-separated EFO terms) and Trim whitespace

```{r}
gbd_long <- gbd_long %>%
  separate_rows(MAPPED_TRAIT_URI, sep = ",") %>%
  mutate(MAPPED_TRAIT_URI = trimws(MAPPED_TRAIT_URI))  

gbd_long
```

Ensure consistent formatting, cleaning and standardize MAPPED_TRAIT_URI in gbd_long (GBD file)

*There are many functions here because each time I attempted to find a matching, I was unable to do so due to the differences in the two datasets. For example, in GWAS, the identifiers have underscores, while in GBD they have colons, and so on... Therefore, the functions below are intended to unify these differences. 

```{r}

# Ensure consistent formatting
gbd_long$MAPPED_TRAIT_URI <- tolower(trimws(gbd_long$MAPPED_TRAIT_URI))

# Ensure lowercase
gbd_long$MAPPED_TRAIT_URI <- tolower(gbd_long$MAPPED_TRAIT_URI) 

# Trim leading/trailing whitespace
gbd_long$MAPPED_TRAIT_URI <- trimws(gbd_long$MAPPED_TRAIT_URI) 

# Remove all spaces
gbd_long$MAPPED_TRAIT_URI <- gsub("\\s+", "", gbd_long$MAPPED_TRAIT_URI) 

# Remove all internal spaces explicitly
gbd_long$MAPPED_TRAIT_URI <- gsub(" ", "", gbd_long$MAPPED_TRAIT_URI) 

# Convert to lowercase and remove spaces 
gbd_long$MAPPED_TRAIT_URI <- tolower(gsub("\\s+", "", gbd_long$MAPPED_TRAIT_URI)) 

# Remove colons and spaces
gbd_long$MAPPED_TRAIT_URI <- gsub("[:\\s]", "", gbd_long$MAPPED_TRAIT_URI)  

# Remove quotation marks
gbd_long$MAPPED_TRAIT_URI <- gsub("\"", "", gbd_long$MAPPED_TRAIT_URI) 

# Replace _ with : 
gbd_long$MAPPED_TRAIT_URI <- gsub("_", ":", gbd_long$MAPPED_TRAIT_URI) 

# Remove all extra spaces
gbd_long$MAPPED_TRAIT_URI <- str_squish(gbd_long$MAPPED_TRAIT_URI) 

(head(gbd_long$MAPPED_TRAIT_URI, 20))

```

Ensure consistent formatting, cleaning and standardize MAPPED_TRAIT_URI in attention (GWAS file)

```{r}

# Function to clean and standardize MAPPED_TRAIT_URI
clean_mapped_trait_uri <- function(uri) {
  # Convert to lowercase
  uri <- tolower(uri)
  # Trim leading/trailing whitespace
  uri <- trimws(uri)
  # Remove all internal spaces explicitly
  uri <- gsub("\\s+", "", uri)
  # Remove quotation marks
  uri <- gsub("\"", "", uri)
  # Replace _ with :
  uri <- gsub("_", ":", uri)
  # Remove colons and spaces
  uri <- gsub("[:\\s]", "", uri)
  # Remove prefixes and ensure consistency
  uri <- sub(".*[:/]", "", uri)
  return(uri)
}

# Apply the function to MAPPED_TRAIT_URI column
attention$MAPPED_TRAIT_URI <- clean_mapped_trait_uri(attention$MAPPED_TRAIT_URI)

(head(attention$MAPPED_TRAIT_URI, 20))


```


Matching GWAS to GBD via MAPPED_TRAIT_URI after cleaning and save the files after removing the duplicates
```{r}

# Merge the data frames
merged_data <- merge(attention, gbd_long, by = "MAPPED_TRAIT_URI", all.x = TRUE)

# Display the first few rows of the merged data frame
head(merged_data)

#  Removing the duplicates 
matched_rows <- inner_join(attention, gbd_long, by = "MAPPED_TRAIT_URI") %>%
  distinct(MAPPED_TRAIT_URI, .keep_all = TRUE)
unmatched_attention <- anti_join(attention, gbd_long, by = "MAPPED_TRAIT_URI") %>%
  distinct(MAPPED_TRAIT_URI, .keep_all = TRUE)
unmatched_gbd <- anti_join(gbd_long, attention, by = "MAPPED_TRAIT_URI") %>%
  distinct(MAPPED_TRAIT_URI, .keep_all = TRUE)

 
#check for any duplicates
duplicates <- unmatched_gbd[duplicated(unmatched_gbd$MAPPED_TRAIT_URI), ]
if (nrow(duplicates) > 0) {
  print("Duplicates found in unmatched_gbd:")
  print(duplicates)
} else {
  print("No duplicates found in unmatched_gbd.")
}

duplicates <- unmatched_attention[duplicated(unmatched_attention$MAPPED_TRAIT_URI), ]
if (nrow(duplicates) > 0) {
  print("Duplicates found in unmatched_attention:")
  print(duplicates)
} else {
  print("No duplicates found in unmatched_attention.")
}

duplicates <- matched_rows[duplicated(matched_rows$MAPPED_TRAIT_URI), ]
if (nrow(duplicates) > 0) {
  print("Duplicates found in matched rows:")
  print(duplicates)
} else {
  print("No duplicates found in matched rows.")
}

# Alternatively here we could have unique by GBD term

# removing duplicates in the gbd_long by "GBD term" NOT MAPPED_TRAIT_URI
unmatched_gbd <- anti_join(gbd_long, attention, by = "MAPPED_TRAIT_URI") %>%
  distinct(`GBD term`, .keep_all = TRUE)
 
  # unique matched rows  by GBD term
matched_rows <- matched_rows %>%
  distinct(`GBD term`, .keep_all = TRUE)

# save the files 
#write.csv(matched_rows, "matched_rows.csv", row.names = FALSE)
#write.csv(unmatched_attention, "unmatched_attention.csv", row.names = FALSE)
#write.csv(unmatched_gbd, "unmatched_gbd.csv", row.names = FALSE)



```

Here we could follow a partial matching approach to handle unmatched GBD terms using "str_detect" function to detect for matching but with different identifiers or GBD present within a string of traits in GWAS

To ensure consistent formatting and standardize of DISEASE/TRAIT in unmatched GBD terms and unmatched attention (GWAS) ie., both lower case for comparison, we will create new columns in both data sets 

```{r}


# Create a new column for disease names to facilitate partial matching in unmatched_attention
unmatched_attention <- unmatched_attention %>%
  mutate(MAPPED_TRAIT_NAME = tolower(trimws(gsub("[^a-zA-Z0-9 ]", "", DISEASE_TRAIT))))

# Create a new column for disease names to facilitate partial matching in gbd_long
unmatched_gbd <- unmatched_gbd%>%
  mutate(GBD_TERM_NAME = tolower(trimws(gsub("[^a-zA-Z0-9 ]", "", unmatched_gbd$`GBD term`))))


# Perform partial matching between MAPPED_TRAIT_NAME in unmatched_attention and GBD_TERM_NAME in gbd_long with the rest of the information 

partial_matches <- unmatched_gbd %>%
  cross_join(unmatched_attention) %>%
  filter(str_detect(MAPPED_TRAIT_NAME, GBD_TERM_NAME)) %>%
  select(
    GBD_TERM_NAME, 
    MAPPED_TRAIT_NAME, 
    GBD_TRAIT_URI = MAPPED_TRAIT_URI.x, 
    ATTENTION_TRAIT_URI = MAPPED_TRAIT_URI.y,
    n, 
    weighted_n, 
    nhits, 
    weighted_nhits, 
    weighted_attention_score_impact_factor,
    `GBD term`
  ) %>%
  distinct()

partial_matches_unique <- partial_matches %>%
  distinct(GBD_TERM_NAME, .keep_all = TRUE)
(head(partial_matches, 20))

#write.csv(partial_matches_unique, "partial_matches_unique.csv", row.names = FALSE)

```

Identify the GBD terms that are not mapped via identifiers or trait with GWAS

```{r}

# Identify the rows that were matched partially
matched_partial_gbd <- partial_matches %>% 
  select(GBD_TRAIT_URI) %>% 
  distinct() %>% 
  rename(MAPPED_TRAIT_URI = GBD_TRAIT_URI)

matched_partial_attention <- partial_matches %>% 
  select(ATTENTION_TRAIT_URI) %>% 
  distinct() %>% 
  rename(MAPPED_TRAIT_URI = ATTENTION_TRAIT_URI)

# Get final unmatched rows
final_unmatched_gbd <- anti_join(unmatched_gbd, matched_partial_gbd, by = "MAPPED_TRAIT_URI")
final_unmatched_attention <- anti_join(unmatched_attention, matched_partial_attention, by = "MAPPED_TRAIT_URI")

# Check for duplicates in final_unmatched_gbd
duplicates_final_unmatched_gbd <- final_unmatched_gbd[duplicated(final_unmatched_gbd$`GBD term`), ]
if (nrow(duplicates_final_unmatched_gbd) > 0) {
  print("Duplicates found in final_unmatched_gbd:")
  print(duplicates_final_unmatched_gbd)
} else {
  print("No duplicates found in final_unmatched_gbd.")
}

# final unmatched 
final_unmatched <- bind_rows(final_unmatched_gbd, final_unmatched_attention)
(head(final_unmatched, 20))

# final matched (combined)
combined_matches <- bind_rows(
  matched_rows %>% mutate(Match_Type = "Identifier"),
  partial_matches_unique %>% mutate(Match_Type = "Partial")
)

# Check for duplicates in combined_matches
duplicates_combined_matches <- combined_matches[duplicated(combined_matches$`GBD term`), ]
if (nrow(duplicates_combined_matches) > 0) {
  print("Duplicates found in combined_matches:")
  print(duplicates_combined_matches)
} else {
  print("No duplicates found in combined_matches.")
}


# Get unique rows in combined_matches based on the "GBD term" column
unique_combined_matches <- combined_matches %>% 
  distinct(`GBD term`, .keep_all = TRUE)

# Check if duplicates still exist
duplicates_combined_matches <- unique_combined_matches[duplicated(unique_combined_matches$`GBD term`), ]
if (nrow(duplicates_combined_matches) > 0) {
  print("Duplicates found in unique_combined_matches:")
  print(duplicates_combined_matches)
} else {
  print("No duplicates found in unique_combined_matches.")
}


# Save the results to a CSV file
#write.csv(final_unmatched, "final_unmatched.csv", row.names = FALSE)


# unique combine matches for all matched terms either by identifiers or by partial matching
#write.csv(unique_combined_matches, "unique combined_matches.csv", row.names = FALSE)

# final unmatched GBD for those unmatched neither by identifiers nor by partial matching
#write.csv(final_unmatched_gbd, "final unmatched_gbd.csv", row.names = FALSE)


```

combine unmatched GBD to attention (GWAS), and  If there are no matches for a GBD trait then the attention score = 0

```{r}


#  Add 'n' column with value 0 to final_unmatched_gbd
final_unmatched_gbd <- final_unmatched_gbd %>%
  mutate(n = 0)

#  Ensure both datasets have the same columns
# Here, we ensure that final_unmatched_gbd has all necessary columns
required_columns <- names(combined_matches)

# Add any missing columns to final_unmatched_gbd and set their values to NA
for (col in required_columns) {
  if (!(col %in% names(final_unmatched_gbd))) {
    final_unmatched_gbd[[col]] <- NA
  }
}

# Combine the datasets
combined_dataset <- bind_rows(unique_combined_matches, final_unmatched_gbd)

combined_dataset <- combined_dataset %>%
  distinct(`GBD term`, .keep_all = TRUE)


# Save the combined dataset to a CSV file
#write.csv(combined_dataset, "combined_dataset.csv", row.names = FALSE)

```

Try to identify any difference or duplicates between combined dataset and the data set that we started with

```{r}


# Get the unique GBD terms in each dataset
combined_gbd_terms <- unique(combined_dataset$`GBD term`)
gbd_gbd_terms <- unique(gbd_data$`GBD term`)

# Identify terms in combined_dataset not in gbd_data
terms_only_in_combined <- setdiff(combined_gbd_terms, gbd_gbd_terms)

# Identify terms in gbd_data not in combined_dataset
terms_only_in_gbd <- setdiff(gbd_gbd_terms, combined_gbd_terms)

# Get the lengths of the unique terms
len_combined <- length(terms_only_in_combined)
len_gbd <- length(terms_only_in_gbd)

# Determine the maximum length to ensure both columns in the data frame have the same number of rows
max_length <- max(len_combined, len_gbd)

# Combine the differences into a data frame for better visualization
diff_df <- data.frame(
  Terms_Only_in_Combined_Dataset = c(terms_only_in_combined, rep(NA, max_length - len_combined)),
  Terms_Only_in_GBD_Dataset = c(terms_only_in_gbd, rep(NA, max_length - len_gbd))
)

# the differences
(diff_df)

# Save the differences to a CSV file
#write.csv(diff_df, "diff_df.csv", row.names = FALSE)

```

Load the GBD DALY data and delete the last row with na result (it is not relevent, just one)

```{r}


# Load the GBD DALY data
gbd_daly_data <- read_csv('/Users/rayanaloliet/Desktop/GWAS Catalog/IHME-GBD_2019_DATA-0912b8a7-1.csv')

# Filter out rows with NA values in the key columns
gbd_daly_data <- gbd_daly_data %>%
  filter(!is.na(`cause_name`), !is.na(val))

# Verify that there are no NA values left
sum(is.na(gbd_daly_data$`cause_name`))
sum(is.na(gbd_daly_data$val))
sum(is.na(gbd_daly_data$measure_name))

 
# Inspect the structure of the GBD DALY data
str(gbd_daly_data)




```


Assessing the relationship between GWAS attention and global need,  using an inequality measure such as Gini coefficients 

```{r}

gbd_daly_data <- gbd_daly_data %>%
  filter(metric_name == "Number" & measure_name == "DALYs (Disability-Adjusted Life Years)") %>%
  rename(`GBD term`= cause_name, DALY = val)

# Merge the DALY values into the combined dataset
combined_dataset <- combined_dataset %>%
  left_join(gbd_daly_data, by = c("GBD term" = "GBD term"))

combined_dataset <- combined_dataset %>%
  distinct(`GBD term`, .keep_all = TRUE)

# Verify the merge
head(combined_dataset)

# Ensure the columns are numeric as it gives error massage 
combined_dataset$n <- as.numeric(combined_dataset$n)
combined_dataset$DALY <- as.numeric(combined_dataset$DALY)

# Check for any NA values and handle them
combined_dataset[is.na(combined_dataset$DALY), 'DALY'] <- 0

# Verify the data
summary(combined_dataset$n)
summary(combined_dataset$DALY)

# Calculate the Gini coefficient
gini_result <- Gini(x = combined_dataset$n, weights = combined_dataset$DALY, conf.level = 0.95)

# the Gini coefficient
(paste("Gini Coefficient: ", gini_result))

```


GBD terms that do not have match, this due to those with no exact mapping such as neglected tropical diseases and maternal disorder.  

```{r}
unmatched_gbd_terms <- anti_join(gbd_daly_data, combined_dataset, by = c("GBD term" = "GBD term"))

unmatched_gbd_terms <- unmatched_gbd_terms %>%
  distinct(`GBD term`, .keep_all = TRUE)

# Get the unique GBD terms in each dataset
combined_gbd_terms <- unique(combined_dataset$`GBD term`)
gbd_gbd_terms <- unique(gbd_daly_data$`GBD term`)

# Identify terms in combined_dataset not in gbd_daly_data
terms_only_in_combined <- setdiff(combined_gbd_terms, gbd_gbd_terms)

# Identify terms in gbd_daly_data not in combined_dataset
terms_only_in_gbd_daly <- setdiff(gbd_gbd_terms, combined_gbd_terms)

# Get the lengths of the unique terms
len_combined <- length(terms_only_in_combined)
len_gbd_daly <- length(terms_only_in_gbd_daly)

# Determine the maximum length to ensure both columns in the data frame have the same number of rows
max_length <- max(len_combined, len_gbd_daly)

# Combine the differences into a data frame for better visualization
diff_2 <- data.frame(
  Terms_Only_in_Combined_Dataset = c(terms_only_in_combined, rep(NA, max_length - len_combined)),
  Terms_Only_in_GBD_Daly_Dataset = c(terms_only_in_gbd_daly, rep(NA, max_length - len_gbd_daly))
)

# the differences
(diff_2)

#write.csv(diff_2, "diff_2.csv", row.names = FALSE)


```

Visualizing the distribution of n and daly 

```{r}

# Visualize the distribution of 'n' (attention scores)
ggplot(combined_dataset, aes(x = n)) +
  geom_histogram(binwidth = 1, fill = 'blue', color = 'black', alpha = 0.7) +
  labs(title = "Histogram of Attention Scores (n)", x = "Attention Score (n)", y = "Frequency")



# Create the histogram for DALY distribution
ggplot(combined_dataset, aes(x = DALY)) +
  geom_histogram(binwidth = 10000, aes(fill = after_stat(count)), color = 'black', alpha = 0.7) +
  scale_fill_gradient(low = "red", high = "darkred") +
  labs(title = "Histogram of DALY", x = "DALY", y = "Frequency") +
  theme_minimal()

# Boxplot for 'n'
ggplot(combined_dataset, aes(y = n)) +
  geom_boxplot(fill = 'blue', color = 'black') +
  labs(title = "Boxplot of Attention Scores (n)", y = "Attention Score (n)")

# Boxplot for 'DALY'
ggplot(combined_dataset, aes(y = DALY)) +
  geom_boxplot(fill = 'red', color = 'black') +
  labs(title = "Boxplot of DALY", y = "DALY")

# Scatter plot to visualize the relationship between 'n' and 'DALY'
ggplot(combined_dataset, aes(x = DALY, y = n)) +
  geom_point(color = 'purple') +
  labs(title = "Scatter Plot of DALY vs Attention Scores (n)", x = "DALY", y = "Attention Score (n)")

# Scatter plot to visualize the relationship between 'weighted_attention_score_impact_factor' and 'DALY'
filtered_dataset <- combined_dataset %>%
  filter(!is.na(DALY) & !is.na(weighted_attention_score_impact_factor))

ggplot(filtered_dataset, aes(x = DALY, y = weighted_attention_score_impact_factor)) +
  geom_point(color = 'blue') +
  labs(title = "Scatter Plot of DALY vs Weighted Attention Score Impact Factor", 
       x = "DALY", 
       y = "Weighted Attention Score Impact Factor")

# Check correlation 
correlation <- cor.test(combined_dataset$n, combined_dataset$DALY, method = "spearman")
(correlation)

summary(combined_dataset$DALY)

```

filtering the data and remove those with n= zero to have a better understating of the other GBD term and visualize the filtered data

```{r}
# check the summary of the n column 
summary(combined_dataset$n)

# Check the count of rows where n is zero
sum(combined_dataset$n == 0)


# Filter out rows with zero attention scores
filtered_dataset <- combined_dataset %>% filter(n > 0)

# Check the summary of the filtered data
summary(filtered_dataset$n)


# Calculate the Gini coefficient using the filtered dataset
gini_result_filtered <- Gini(x = filtered_dataset$n, weights = filtered_dataset$DALY, conf.level = 0.95)

# the Gini coefficient
(paste("Gini Coefficient (Filtered): ", gini_result_filtered))


# Summary of 'n' in the filtered dataset
summary(filtered_dataset$n)

# Summary of 'DALY' in the filtered dataset
summary(filtered_dataset$DALY)




# Histogram of Attention Scores (n)
ggplot(filtered_dataset, aes(x = n)) +
  geom_histogram(binwidth = 1, fill = 'blue', color = 'black', alpha = 0.7) +
  labs(title = "Histogram of Attention Scores (n) - Filtered", x = "Attention Score (n)", y = "Frequency")

# Boxplot of Attention Scores (n)
ggplot(filtered_dataset, aes(y = n)) +
  geom_boxplot(fill = 'blue', color = 'black') +
  labs(title = "Boxplot of Attention Scores (n) - Filtered", y = "Attention Score (n)")



# Create the histogram for DALY distribution with a larger binwidth
ggplot(filtered_dataset, aes(x = DALY)) +
  geom_histogram(binwidth = 10000, aes(fill = after_stat(count)), color = 'black', alpha = 0.7) +
  scale_fill_gradient(low = "red", high = "darkred") +
  labs(title = "Histogram of DALY Values- Filtered", x = "DALY", y = "Frequency") +
  theme_minimal()

# Boxplot of DALY values
ggplot(filtered_dataset, aes(y = DALY)) +
  geom_boxplot(fill = 'red', color = 'black') +
  labs(title = "Boxplot of DALY Values- Filtered", y = "DALY")

# Check correlation 
correlation_filtered <- cor.test(filtered_dataset$n, filtered_dataset$DALY, method = "spearman")
(correlation_filtered)


```

Investigate Specific Diseases: Identify specific diseases with high DALY but low attention scores

a threshold for low attention: Here, I have used n <= 1 as the threshold for low attention. 

```{r}
# Filter for diseases with high DALY but low attention scores
threshold_attention = 1  # Define what is considered low attention
high_daly_low_attention <- combined_dataset %>%
  filter(DALY > median(DALY) & n <= threshold_attention) %>%
  arrange(desc(DALY))

# View the top diseases with high DALY and low attention
(head(high_daly_low_attention, 20))

# Save the filtered data to a CSV file
#write.csv(high_daly_low_attention, "high_daly_low_attention.csv", row.names = FALSE)


```



