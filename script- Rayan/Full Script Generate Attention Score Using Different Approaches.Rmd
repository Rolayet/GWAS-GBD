---
title: "Generate Attention Score Using Different Approaches: EFO Term, Weighted_n, nhits, weighted_nhits and weighted_attention_score_impact_factor"

output: html_notebook
---
 

Read the GWAS Catalog data and Load necessary libraries


```{r}
# Load necessary libraries

library(dplyr)
library(data.table)
library(tidyr)
library(stringr)
library(DescTools)
library(ggplot2)
library(stats)
library(readr)
library(ontologyIndex)
library(readxl)
library(openxlsx)
library(boot)
library(LorenzRegression)


a <- read_xlsx("gwas_catalog_v1.0.2.1-studies_r2024-06-07.xlsx")
 


```



Have a look at the data

```{r}
hist(a$`ASSOCIATION COUNT`, breaks=100)
```

Sometimes there is more than one EFO term (comma separated). Split them into separate lines

```{r}

head(a, 10)

a <- a %>%
    tidyr::separate_rows(MAPPED_TRAIT_URI, sep = ", ")

head(a, 10)

```

Get the number of EFO terms per publication

```{r}
pubmed_count <- a %>% group_by(PUBMEDID) %>% 
    summarise(
        n_efo = length(unique(MAPPED_TRAIT_URI))
    ) %>% arrange(desc(n_efo))

pubmed_count

```

Add the EFO count per PUBMEDID to the data frame

```{r}
a <- left_join(a, pubmed_count, by="PUBMEDID")
str(a)
```

Step 1. Develop the attention scores

- n = number of studies with that EFO term
- weighted_n = weighted by number of EFO terms in the study in total
- nhits = number of GWAS hits reported for that EFO term
- weighted_nhits = nhits weighted by number of EFO terms in the study in total

```{r}
attention <- a %>% group_by(
    MAPPED_TRAIT_URI
) %>% 
    summarise(
        n = n(), 
        weighted_n = sum(1/n_efo),
        nhits = sum(`ASSOCIATION COUNT`),
        weighted_nhits = sum(`ASSOCIATION COUNT` / n_efo)
    )

str(attention)

```

Removing extra whitespace, cleaning the Impact factor values and ensure the values are numeric 

```{r}
# Remove extra whitespace
a$`Impact factor` <- trimws(a$`Impact factor`)

# Replace non-standard characters
a$`Impact factor` <- gsub("Â·", ".", a$`Impact factor`)

# Convert to numeric, forcing non-numeric values to NA (for those with no impact factors)
a$`Impact factor` <- as.numeric(a$`Impact factor`)

# Replace NA values with 0
a$`Impact factor`[is.na(a$`Impact factor`)] <- 0

# Verify the changes
str(a)
unique(a$`Impact factor`)
summary(a$`Impact factor`)


```

 Including the impact factor values after preparing and cleaning the attention scores. Additionally, we have added the PUBMEDID to ensure that the studies are independent when we sum up the "n." We also added DISEASE/TRAIT for matching via str_detect function if we did not find a match via EFO terms. 
 
```{r}


# Including the impact factor and (`DISEASE/TRAIT`) column for matching and PUBMEDID to ensure the the studies are independent during the mapping process 

attention <- a %>%
  group_by(MAPPED_TRAIT_URI) %>%
  summarise(
    n = n(), 
    weighted_n = sum(1 / n_efo),
    nhits = sum(`ASSOCIATION COUNT`),
    weighted_nhits = sum(`ASSOCIATION COUNT` / n_efo),
    weighted_attention_score_impact_factor = sum((1 / n_efo) * `Impact factor`, na.rm = TRUE),
     DISEASE_TRAIT = paste(unique(`DISEASE/TRAIT`), collapse = "; "),
    PUBMEDID = paste(unique(PUBMEDID), collapse = ", ")
  )


# Expand PUBMEDID into separate rows
attention <- attention %>%
  separate_rows(PUBMEDID, sep = ", ") 


str(attention)

```
 
Step 2: Merging the GWAS attention scores with the GBD disease burden results. The GBD terms were split into first part (single gbd term, without descendants) and second parts (with descendants) because the terms in the second part have descendants. Therefore, those in the second part need to be handled differently, where we have to pull out the descendants from the tree via ontologyIndex library and then do the matching.


```{r}

First_part_GBD<- read_xlsx("First_part_GBD.xlsx")

str(First_part_GBD)

  # unique matched rows  by GBD term
First_part_GBD<- First_part_GBD%>%
  distinct(`GBD term`, .keep_all = TRUE)

 
```

Include only GBD terms at levels 3 and 4 within the Communicable and Non-Communicable Diseases categories (308 terms).

This means:

Exclude all terms at levels 0, 1, and 2 under the Communicable Diseases, Non-Communicable Diseases, Injury, and All Causes categories (32 terms).

Exclude the rest of gbd terms in the Injury category at levels 3 and 4 (37 terms).

Notes: The total number of GBD terms across all categories and levels is 377. All Causes category does not have gbd terms in level 3 and 4

```{r}
# List of causes in level 0, 1 and 2 to exclude in Communicable Diseases, Non-Communicable Diseases, Injury and All Causes categories

exclude_causes <- c(
  "All causes", 
  "Communicable, maternal, neonatal, and nutritional diseases",
  "HIV/AIDS and sexually transmitted infections",
  "Respiratory infections and tuberculosis",
  "Enteric infections",
  "Neglected tropical diseases and malaria",
  "Other infectious diseases",
  "Maternal and neonatal disorders",
  "Nutritional deficiencies",
  "Non-communicable diseases",
  "Neoplasms",
  "Cardiovascular diseases",
  "Chronic respiratory diseases",
  "Digestive diseases",
  "Neurological disorders",
  "Mental disorders",
  "Substance use disorders",
  "Diabetes and kidney diseases",
  "Skin and subcutaneous diseases",
  "Sense organ diseases",
  "Musculoskeletal disorders",
  "Other non-communicable diseases",
  "Injuries",
  "Transport injuries",
  "Unintentional injuries",
  "Self-harm and interpersonal violence",
  "Other COVID-19 pandemic-related outcomes",
  "Total cancers",
  "Total burden related to hepatitis B",
  "Total burden related to hepatitis C",
  "Total burden related to Non-alcoholic fatty liver disease (NAFLD)",
  "Total Cancers excluding Non-melanoma skin cancer"
)

# Filter the dataset to exclude the specified causes
First_part_GBD <- First_part_GBD %>%
  filter(!`GBD term` %in% exclude_causes)

# Additional causes under injuries category to exclude in level 3 and 4 

additional_exclude_causes <- c(
  "Road injuries",
  "Pedestrian road injuries",
  "Cyclist road injuries",
  "Motorcyclist road injuries",
  "Motor vehicle road injuries",
  "Other road injuries",
  "Other transport injuries",
  "Falls",
  "Drowning",
  "Fire, heat, and hot substances",
  "Poisonings",
  "Poisoning by carbon monoxide",
  "Poisoning by other means",
  "Exposure to mechanical forces",
  "Unintentional firearm injuries",
  "Other exposure to mechanical forces",
  "Adverse effects of medical treatment",
  "Animal contact",
  "Venomous animal contact",
  "Non-venomous animal contact",
  "Foreign body",
  "Pulmonary aspiration and foreign body in airway",
  "Foreign body in eyes",
  "Foreign body in other body part",
  "Environmental heat and cold exposure",
  "Exposure to forces of nature",
  "Other unintentional injuries",
  "Self-harm",
  "Self-harm by firearm",
  "Self-harm by other specified means",
  "Interpersonal violence",
  "Physical violence by firearm",
  "Physical violence by sharp object",
  "Sexual violence",
  "Physical violence by other means",
  "Conflict and terrorism",
  "Police conflict and executions"
)

# Combine the original exclude list with the additional causes
exclude_causes <- c(exclude_causes, additional_exclude_causes)

# Filter the dataset to exclude the specified causes
First_part_GBD <- First_part_GBD %>%
  filter(!`GBD term` %in% exclude_causes)
```

Specify columns that contain EFO terms

```{r}

efo_columns <- c("EFO 1", "EFO 2", "EFO 3", "EFO 4", "EFO 5", "EFO 6", 
                 "EFO 7", "EFO 8", "EFO 9", "EFO 10", "EFO 11", "EFO 12",
                 "EFO 13", "EFO 14", "EFO 15", "EFO 16", "EFO 17", "EFO 18",
                 "EFO 19", "EFO 20", "EFO 21", "EFO 22", "EFO 23", "EFO 24",
                 "EFO 25", "EFO 26", "EFO 27", "EFO 28", "EFO 29", "EFO 30")
```


Reshape the GBD data to gather all relevant columns into key-value pairs and drop rows with NA EFO terms

```{r}

 gbd_long <- First_part_GBD%>%
pivot_longer(cols = all_of(efo_columns), names_to = "EFO_number", values_to =  "MAPPED_TRAIT_URI") %>% drop_na(MAPPED_TRAIT_URI) 

gbd_long
```


Ensure consistent formatting, cleaning and standardize MAPPED_TRAIT_URI in gbd_long (GBD file)

*There are many functions here because each time I attempted to find a matching, I was unable to do so due to the differences in the two datasets. For example, in GWAS, the identifiers have underscores, while in GBD they have colons, and so on... Therefore, the functions below are intended to unify these differences. 

```{r}

# Ensure consistent formatting
gbd_long$MAPPED_TRAIT_URI <- tolower(trimws(gbd_long$MAPPED_TRAIT_URI))

# Ensure lowercase
gbd_long$MAPPED_TRAIT_URI <- tolower(gbd_long$MAPPED_TRAIT_URI) 

# Trim leading/trailing whitespace
gbd_long$MAPPED_TRAIT_URI <- trimws(gbd_long$MAPPED_TRAIT_URI) 

# Remove all spaces
gbd_long$MAPPED_TRAIT_URI <- gsub("\\s+", "", gbd_long$MAPPED_TRAIT_URI) 

# Remove all internal spaces explicitly
gbd_long$MAPPED_TRAIT_URI <- gsub(" ", "", gbd_long$MAPPED_TRAIT_URI) 

# Convert to lowercase and remove spaces 
gbd_long$MAPPED_TRAIT_URI <- tolower(gsub("\\s+", "", gbd_long$MAPPED_TRAIT_URI)) 

# Remove colons and spaces
gbd_long$MAPPED_TRAIT_URI <- gsub("[:\\s]", "", gbd_long$MAPPED_TRAIT_URI)  

# Remove quotation marks
gbd_long$MAPPED_TRAIT_URI <- gsub("\"", "", gbd_long$MAPPED_TRAIT_URI) 

# Replace _ with : 
gbd_long$MAPPED_TRAIT_URI <- gsub("_", ":", gbd_long$MAPPED_TRAIT_URI) 

# Remove all extra spaces
gbd_long$MAPPED_TRAIT_URI <- str_squish(gbd_long$MAPPED_TRAIT_URI) 

(head(gbd_long$MAPPED_TRAIT_URI, 20))

```

Ensure consistent formatting, cleaning and standardize MAPPED_TRAIT_URI in attention (GWAS file) and remove rows with NA in MAPPED_TRAIT_URI (EFO terms)

```{r}
# Function to clean and standardize MAPPED_TRAIT_URI
clean_mapped_trait_uri <- function(uri) {
  # Convert to lowercase
  uri <- tolower(uri)
  # Trim leading/trailing whitespace
  uri <- trimws(uri)
  # Remove all internal spaces explicitly
  uri <- gsub("\\s+", "", uri)
  # Remove quotation marks
  uri <- gsub("\"", "", uri)
  # Replace _ with :
  uri <- gsub("_", ":", uri)
  # Remove colons and spaces
  uri <- gsub("[:\\s]", "", uri)
  # Remove prefixes and ensure consistency
  uri <- sub(".*[:/]", "", uri)
  return(uri)
}

# Apply the function to MAPPED_TRAIT_URI column
attention$MAPPED_TRAIT_URI <- clean_mapped_trait_uri(attention$MAPPED_TRAIT_URI)


# Convert "na" strings to actual NA values
attention$MAPPED_TRAIT_URI[attention$MAPPED_TRAIT_URI == "na"] <- NA

# Remove rows with NA in MAPPED_TRAIT_URI
attention <- attention %>%
  filter(!is.na(MAPPED_TRAIT_URI))

(head(attention$MAPPED_TRAIT_URI, 20))

```

step 3: Finding a match between GWAS and GBD (First_part_GBD) via identifiers (EFO terms)- for those with no descendants. Then grouping those terms by GBD term and PUBMEDID (as we need to ensure the studies are independent when we sum the n ).


```{r}

# Merge the data frames
merged_data <- merge(attention, gbd_long, by = "MAPPED_TRAIT_URI", all.x = TRUE)

# Identify matched rows
matched_rows <- inner_join(attention, gbd_long, by = "MAPPED_TRAIT_URI")

 
 # Group by GBD term and PUBMEDID and summarize within these groups 
 matched_rows_unique <- matched_rows %>%
    group_by(`GBD term`, PUBMEDID) %>%
    summarise(
      total_attention_score_per_pubmed = sum(n, na.rm = TRUE),
      weighted_n = sum(weighted_n),
      nhits = sum(nhits),
      weighted_nhits = sum(weighted_nhits),
      weighted_attention_score_impact_factor = sum(weighted_attention_score_impact_factor),
      .groups = "drop"
    )
 
      # Now summarize these attention scores across the GBD term and sum the total_attention_score_per_pubmed 
  unique_matched_gbd_terms_First_part_GBD <- matched_rows_unique %>%
    group_by(`GBD term`) %>%
    summarise(
      total_attention_score = sum(total_attention_score_per_pubmed, na.rm = TRUE),
      weighted_n = sum(weighted_n),
      nhits = sum(nhits),
      weighted_nhits = sum(weighted_nhits),
      weighted_attention_score_impact_factor = sum(weighted_attention_score_impact_factor),
      .groups = "drop"
    )
 
   
# Identify unmatched rows from attention
unmatched_attention <- anti_join(attention, gbd_long, by = "MAPPED_TRAIT_URI")

# Identify unmatched rows from gbd_long
unmatched_gbd <- anti_join(gbd_long, attention, by = "MAPPED_TRAIT_URI")

# Ensure unique unmatched_gbd rows by GBD term
unmatched_gbd_unique <- unmatched_gbd %>%
  distinct(`GBD term`, .keep_all = TRUE)

# Extract unique GBD terms for matched and unmatched entries
matched_gbd_terms <- matched_rows_unique$`GBD term` %>% unique()
unmatched_gbd_terms <- unmatched_gbd_unique$`GBD term` %>% unique()

# Remove any GBD terms from unmatched_gbd that are also in matched_rows
unique_unmatched_gbd_terms <- setdiff(unmatched_gbd_terms, matched_gbd_terms)

# Ensure unique unmatched_gbd rows by GBD term
unique_unmatched_gbd_terms_First_part_GBD <- unmatched_gbd_unique %>%
  filter(`GBD term` %in% unique_unmatched_gbd_terms)

# Save the data frames to Excel files
#write.xlsx(unique_matched_gbd_terms_First_part_GBD, "unique_matched_gbd_terms_First_part_GBD.xlsx")
#write.xlsx(unique_unmatched_gbd_terms_First_part_GBD, "unique_unmatched_gbd_terms_First_part_GBD.xlsx")

```


Verification of the summing up of n in total_attention_score_per_pubmed "as long as they are independent publications" (all PUBMEDID are unique)

```{r}

# Select a specific GBD term for manual verification
selected_gbd_term <- "Acne vulgaris"  # Example term

# Filter the intermediate summarization for the selected GBD term
filtered_intermediate <- matched_rows_unique %>%
  filter(`GBD term` == selected_gbd_term)

# Print the filtered data for manual verification
print(filtered_intermediate)

# Sum the `n` values manually for verification
manual_sum_n <- sum(filtered_intermediate$total_attention_score_per_pubmed)
print(paste("Manual sum of n for", selected_gbd_term, ":", manual_sum_n))

```


Finding a match between GWAS and GBD (Second_part_GBD) via identifiers- for those with  descendants. We need to change the format of the identifiers again to get the descendants using the ontology from the tree then reverse it again to match it with GWAS (to ensure the consistency in the matching process). Also, as we did not part one, we will group them by GBD term and PUBMEDID. 


```{r}


# Define utility functions
format_identifier <- function(identifier) {
  formatted <- gsub(" ", "", identifier) # Remove any spaces
  formatted <- toupper(formatted) # Convert to uppercase
  formatted <- gsub("([A-Z]+)([0-9]+)", "\\1:\\2", formatted) # Add colon
  return(formatted)
}

revert_identifier <- function(identifier) {
  reverted <- gsub(":", "", identifier) # Remove colons
  return(tolower(reverted)) # Convert to lowercase
}

clean_mapped_trait_uri <- function(uri) {
  uri <- tolower(uri) # Convert to lowercase
  uri <- trimws(uri) # Trim leading/trailing whitespace
  uri <- gsub("\\s+", "", uri) # Remove all internal spaces explicitly
  uri <- gsub("\"", "", uri) # Remove quotation marks
  uri <- gsub("_", ":", uri) # Replace _ with :
  uri <- gsub("[:\\s]", "", uri) # Remove colons and spaces
  uri <- sub(".*[:/]", "", uri) # Remove prefixes and ensure consistency
  return(uri)
}

# Read data file (Due to the file size, it can be downloaded from: https://www.ebi.ac.uk/efo/)

ontology <- get_OBO("efo-obo.txt")

Second_part_GBD <- read_excel("Second_part_GBD.xlsx")


# List of causes in level 0, 1 and 2 to exclude in Communicable Diseases, Non-Communicable Diseases, Injury and All Causes categories

exclude_causes <- c(
  "All causes", 
  "Communicable, maternal, neonatal, and nutritional diseases",
  "HIV/AIDS and sexually transmitted infections",
  "Respiratory infections and tuberculosis",
  "Enteric infections",
  "Neglected tropical diseases and malaria",
  "Other infectious diseases",
  "Maternal and neonatal disorders",
  "Nutritional deficiencies",
  "Non-communicable diseases",
  "Neoplasms",
  "Cardiovascular diseases",
  "Chronic respiratory diseases",
  "Digestive diseases",
  "Neurological disorders",
  "Mental disorders",
  "Substance use disorders",
  "Diabetes and kidney diseases",
  "Skin and subcutaneous diseases",
  "Sense organ diseases",
  "Musculoskeletal disorders",
  "Other non-communicable diseases",
  "Injuries",
  "Transport injuries",
  "Unintentional injuries",
  "Self-harm and interpersonal violence",
  "Other COVID-19 pandemic-related outcomes",
  "Total cancers",
  "Total burden related to hepatitis B",
  "Total burden related to hepatitis C",
  "Total burden related to Non-alcoholic fatty liver disease (NAFLD)",
  "Total Cancers excluding Non-melanoma skin cancer"
)

# Filter the dataset to exclude the specified causes
Second_part_GBD <- Second_part_GBD %>%
  filter(!`GBD term` %in% exclude_causes)

# Additional causes under injuries category to exclude (37)
additional_exclude_causes <- c(
  "Road injuries",
  "Pedestrian road injuries",
  "Cyclist road injuries",
  "Motorcyclist road injuries",
  "Motor vehicle road injuries",
  "Other road injuries",
  "Other transport injuries",
  "Falls",
  "Drowning",
  "Fire, heat, and hot substances",
  "Poisonings",
  "Poisoning by carbon monoxide",
  "Poisoning by other means",
  "Exposure to mechanical forces",
  "Unintentional firearm injuries",
  "Other exposure to mechanical forces",
  "Adverse effects of medical treatment",
  "Animal contact",
  "Venomous animal contact",
  "Non-venomous animal contact",
  "Foreign body",
  "Pulmonary aspiration and foreign body in airway",
  "Foreign body in eyes",
  "Foreign body in other body part",
  "Environmental heat and cold exposure",
  "Exposure to forces of nature",
  "Other unintentional injuries",
  "Self-harm",
  "Self-harm by firearm",
  "Self-harm by other specified means",
  "Interpersonal violence",
  "Physical violence by firearm",
  "Physical violence by sharp object",
  "Sexual violence",
  "Physical violence by other means",
  "Conflict and terrorism",
  "Police conflict and executions"
)

# Combine the original exclude list with the additional causes
exclude_causes <- c(exclude_causes, additional_exclude_causes)

# Filter the dataset to exclude the specified causes
Second_part_GBD <- Second_part_GBD %>%
  filter(!`GBD term` %in% exclude_causes)

# Extract and combine identifiers from Second_part_GBD
identifiers_list <- list(
  Second_part_GBD$`MAPPED_TRAIT_URI...2`,
  Second_part_GBD$`MAPPED_TRAIT_URI...3`,
  Second_part_GBD$`MAPPED_TRAIT_URI...4`,
  Second_part_GBD$`MAPPED_TRAIT_URI...5`,
  Second_part_GBD$`MAPPED_TRAIT_URI...6`,
  Second_part_GBD$`MAPPED_TRAIT_URI...7`,
  Second_part_GBD$`MAPPED_TRAIT_URI...8`,
  Second_part_GBD$`MAPPED_TRAIT_URI...9`,
  Second_part_GBD$`MAPPED_TRAIT_URI...10`,
  Second_part_GBD$`MAPPED_TRAIT_URI...11`,
  Second_part_GBD$`MAPPED_TRAIT_URI...12`,
  Second_part_GBD$`MAPPED_TRAIT_URI...13`
)
identifiers <- do.call(c, lapply(identifiers_list, na.omit))

# Format the identifiers
formatted_identifiers <- sapply(identifiers, format_identifier)

# Extract descendants for each identifier
descendants_list <- list()
for (i in 1:length(formatted_identifiers)) {
  id <- formatted_identifiers[i]
  if (id %in% ontology$id) {
    descendants <- get_descendants(ontology, id)
    descendants_list[[id]] <- descendants
  } else {
    descendants_list[[id]] <- NA
  }
}

# Determine the maximum number of descendants
max_descendants <- max(sapply(descendants_list, function(x) if (is.null(x) || all(is.na(x))) 0 else length(x)), na.rm = TRUE)

# Create a data frame for descendants
descendants_df <- data.frame(MAPPED_TRAIT_URI = character(), stringsAsFactors = FALSE)
for (i in 1:max_descendants) {
  descendants_df[paste0("Descendant_", i)] <- character()
}

# Populate the data frame with identifiers and their descendants
for (i in seq_along(formatted_identifiers)) {
  id <- formatted_identifiers[i]
  descendants <- descendants_list[[id]]
  if (is.null(descendants) || all(is.na(descendants))) {
    row <- c(MAPPED_TRAIT_URI = id, rep("", max_descendants))
  } else {
    row <- c(MAPPED_TRAIT_URI = id, descendants, rep("", max_descendants - length(descendants)))
  }
  
  row_df <- as.data.frame(t(row), stringsAsFactors = FALSE)
  colnames(row_df) <- colnames(descendants_df)
  descendants_df <- rbind(descendants_df, row_df)
}

# Convert columns to character type
descendants_df[] <- lapply(descendants_df, as.character)

# Add the GBD_TERM column
gbd_terms <- Second_part_GBD$`GBD term`
descendants_df$GBD_TERM <- gbd_terms[match(descendants_df$MAPPED_TRAIT_URI, formatted_identifiers)]

# Reorder columns to place GBD_TERM after MAPPED_TRAIT_URI
if ("GBD_TERM" %in% colnames(descendants_df)) {
  descendants_df <- descendants_df %>% select(MAPPED_TRAIT_URI, GBD_TERM, everything())
}

# Revert the identifiers to their original format
descendants_df <- descendants_df %>% mutate(across(c(MAPPED_TRAIT_URI, starts_with("Descendant_")), ~sapply(., revert_identifier)))

# Ensure identifiers are formatted correctly in attention
attention <- attention %>% mutate(MAPPED_TRAIT_URI = format_identifier(MAPPED_TRAIT_URI))

# Remove duplicates in both data frames
attention <- attention %>% distinct(MAPPED_TRAIT_URI, .keep_all = TRUE)
descendants_df <- descendants_df %>% distinct(MAPPED_TRAIT_URI, .keep_all = TRUE)

# Reshape descendants_df to long format
descendants_long <- descendants_df %>%
  pivot_longer(cols = starts_with("Descendant_"), names_to = "Descendant", values_to = "Descendant_URI") %>%
  filter(Descendant_URI != "") %>%
  select(MAPPED_TRAIT_URI, GBD_TERM, Descendant_URI)

# Clean and standardize Descendant_URI
descendants_long$Descendant_URI <- tolower(trimws(descendants_long$Descendant_URI))
descendants_long$Descendant_URI <- gsub("\\s+", "", descendants_long$Descendant_URI)
descendants_long$Descendant_URI <- gsub(" ", "", descendants_long$Descendant_URI)
descendants_long$Descendant_URI <- gsub("[:\\s]", "", descendants_long$Descendant_URI)
descendants_long$Descendant_URI <- gsub("\"", "", descendants_long$Descendant_URI)
descendants_long$Descendant_URI <- gsub("_", ":", descendants_long$Descendant_URI)
descendants_long$Descendant_URI <- str_squish(descendants_long$Descendant_URI)
descendants_long <- descendants_long %>% distinct(Descendant_URI, .keep_all = TRUE)

# Clean and standardize MAPPED_TRAIT_URI in attention
attention$MAPPED_TRAIT_URI <- clean_mapped_trait_uri(attention$MAPPED_TRAIT_URI)

# Identify matched entries
matched_entries <- attention %>%
  filter(MAPPED_TRAIT_URI %in% descendants_long$Descendant_URI) %>%
  left_join(descendants_long %>% select(Descendant_URI, GBD_TERM), by = c("MAPPED_TRAIT_URI" = "Descendant_URI"))


 # Group by GBD term and PUBMEDID and summarize within these groups and drop na 
 matched_entries_unique <- matched_entries %>% 
    drop_na() %>%
    group_by(GBD_TERM, PUBMEDID) %>%
    summarise(
      total_attention_score_per_pubmed = sum(n, na.rm = TRUE),
      weighted_n = sum(weighted_n),
      nhits = sum(nhits),
      weighted_nhits = sum(weighted_nhits),
      weighted_attention_score_impact_factor = sum(weighted_attention_score_impact_factor),
      .groups = "drop"
    )


     # Now summarize these attention scores across the GBD term and sum the total_attention_score_per_pubmed 
  unique_matched_gbd_terms_Second_part_GBD <- matched_entries_unique %>%
    group_by(GBD_TERM) %>%
    summarise(
      total_attention_score = sum(total_attention_score_per_pubmed, na.rm = TRUE),
      weighted_n = sum(weighted_n),
      nhits = sum(nhits),
      weighted_nhits = sum(weighted_nhits),
      weighted_attention_score_impact_factor = sum(weighted_attention_score_impact_factor),
      .groups = "drop"
    )
  
# Identify unmatched GBD entries based on GBD_TERM in both datasets
# First, extract unique GBD terms from both datasets
matched_gbd_terms <- matched_entries$GBD_TERM %>% unique()
unmatched_gbd_terms <- Second_part_GBD$`GBD term` %>% unique()

# Identify unmatched GBD terms
unique_unmatched_gbd_terms <- setdiff(unmatched_gbd_terms, matched_gbd_terms)

# Filter the Second_part_GBD dataframe to get rows with these unique unmatched GBD terms
unique_unmatched_gbd_terms_Second_part_GBD <- Second_part_GBD %>%
  filter(`GBD term` %in% unique_unmatched_gbd_terms)

# Save the data frames to Excel files
#write.xlsx(unique_unmatched_gbd_terms_Second_part_GBD, unique_unmatched_gbd_terms_Second_part_GBD.xlsx")
#write.xlsx(unique_matched_gbd_terms_Second_part_GBD, "unique_matched_gbd_terms_Second_part_GBD.xlsx")

```

Combining the results for the unmatched and matched GBDs



```{r}

# List of columns to keep for unmatched terms
columns_unmatched <- c("GBD term")

# Select only the necessary columns from the first unmatched data frame
unique_unmatched_gbd_terms_First_part_GBD <- unique_unmatched_gbd_terms_First_part_GBD[, columns_unmatched]


# Select and order the columns to match the first unmatched data frame
unique_unmatched_gbd_terms_Second_part_GBD <- unique_unmatched_gbd_terms_Second_part_GBD[, columns_unmatched]

# Combine the unmatched terms
combined_unmatched_terms <- rbind(unique_unmatched_gbd_terms_First_part_GBD, unique_unmatched_gbd_terms_Second_part_GBD)

# Display the results
print("Combined Unmatched Terms:")
print(combined_unmatched_terms)


# Rename the column in the second matched data frame
names(unique_matched_gbd_terms_Second_part_GBD)[which(names(unique_matched_gbd_terms_Second_part_GBD) == "GBD_TERM")] <- "GBD term"



# Combine the matched terms
combined_matched_terms <- rbind(unique_matched_gbd_terms_First_part_GBD, unique_matched_gbd_terms_Second_part_GBD)

# Display the results
print("Combined Matched Terms:")
print(combined_matched_terms)

# Save the data frames to Excel files
#write.xlsx(combined_matched_terms, combined_matched_terms.xlsx")
#write.xlsx(combined_unmatched_terms, "combined_unmatched_terms.xlsx")


```

Here we could follow a partial matching approach to handle unmatched GBD terms using "str_detect" function to detect for matching but with different identifiers or GBD present within a string of traits in GWAS.

*This approach is helpful because sometimes we may miss EFO terms in the mapping process during manual mapping i.e there are many EFO terms for a particular GBD, this will be capture using str_detect" function.

To ensure consistent formatting and standardize of DISEASE/TRAIT in unmatched GBD terms and unmatched attention (GWAS) ie., both lower case for comparison, we will create new columns in both data sets 


```{r}
# Create a new column for disease names to facilitate partial matching in attention
attention <- attention %>%
  mutate(TRAIT_NAME = tolower(trimws(gsub("[^a-zA-Z0-9 ]", "", DISEASE_TRAIT))))

# Create a new column for disease names to facilitate partial matching in combined_unmatched_terms
combined_unmatched_terms <- combined_unmatched_terms%>%
  mutate(GBD_TERM_NAME = tolower(trimws(gsub("[^a-zA-Z0-9 ]", "", combined_unmatched_terms$`GBD term`))))


# Perform partial matching between TRAIT_NAME in attention and GBD_TERM_NAME in combined_unmatched_terms with the rest of the information 
partial_matches <- combined_unmatched_terms %>%
  cross_join(attention) %>%
  filter(str_detect(TRAIT_NAME, GBD_TERM_NAME)) %>%
  select(
    n, 
    weighted_n, 
    nhits, 
    weighted_nhits, 
    weighted_attention_score_impact_factor,
    PUBMEDID,
    `GBD term`
  ) %>%
  distinct()



# Group by GBD term and PUBMEDID and summarize within these groups 
 partial_matches_filtered <- partial_matches %>%
    group_by(`GBD term`, PUBMEDID) %>%
    summarise(
      total_attention_score_per_pubmed = sum(n, na.rm = TRUE),
      weighted_n = sum(weighted_n),
      nhits = sum(nhits),
      weighted_nhits = sum(weighted_nhits),
      weighted_attention_score_impact_factor = sum(weighted_attention_score_impact_factor),
      .groups = "drop"
    )
 
     # Now summarize these attention scores across the GBD term and sum the total_attention_score_per_pubmed 
  partial_matches_unique <- partial_matches_filtered %>%
    group_by(`GBD term`) %>%
    summarise(
      total_attention_score = sum(total_attention_score_per_pubmed, na.rm = TRUE),
      weighted_n = sum(weighted_n),
      nhits = sum(nhits),
      weighted_nhits = sum(weighted_nhits),
      weighted_attention_score_impact_factor = sum(weighted_attention_score_impact_factor),
      .groups = "drop"
    )



```


Identify the GBD terms that are not mapped via identifiers or trait with GWAS to combine them in one dataset. Now we will have final_matched_gbd and final_unmatched_gbd. 

```{r}


# Identify the rows that were matched partially
matched_partial_gbd <- partial_matches_unique %>% 
  select(`GBD term`) %>% 
  distinct() 

# Get final unmatched rows
final_unmatched_gbd <- anti_join(combined_unmatched_terms, matched_partial_gbd, by = "GBD term")


# Check for duplicates in final_unmatched_gbd
duplicates_final_unmatched_gbd <- final_unmatched_gbd[duplicated(final_unmatched_gbd$`GBD term`), ]
if (nrow(duplicates_final_unmatched_gbd) > 0) {
  print("Duplicates found in final_unmatched_gbd:")
  print(duplicates_final_unmatched_gbd)
} else {
  print("No duplicates found in final_unmatched_gbd.")
}


# final matched_gbd (combine those identified via Identifier and Partially)
final_matched_gbd <- bind_rows(
  combined_matched_terms %>% mutate(Match_Type = "Identifier"),
  partial_matches_unique %>% mutate(Match_Type = "Partial")
)

# Check for duplicates in final matched_gbd
duplicates_final_matched_gbd <- final_matched_gbd[duplicated(final_matched_gbd$`GBD term`), ]
if (nrow(duplicates_final_matched_gbd) > 0) {
  print("Duplicates found in final_matched_gbd:")
  print(duplicates_final_matched_gbd)
} else {
  print("No duplicates found in final_matched_gbd")
}


# Save the results to a CSV file
#write.csv(final_unmatched_gbd, "final_unmatched_gbd.csv", row.names = FALSE)
#write.csv(final_matched_gbd, "final_matched_gbd.csv", row.names = FALSE)


```


If there are no matches for a GBD trait then the attention score = 0. Also, we ill combine matched and unmatched GBD terms in one data set (combined dataset). It has 308 GBD terms, as we started. 

```{r}


#  Add 'total_attention_score' column with value 0 to final_unmatched_gbd
final_unmatched_gbd <- final_unmatched_gbd %>%
  mutate(total_attention_score = 0)


# Combine the datasets and remove duplicate 
combined_dataset <- bind_rows(final_matched_gbd, final_unmatched_gbd)

combined_dataset <- combined_dataset %>%
  distinct(`GBD term`, .keep_all = TRUE)


# remove the column
combined_dataset <- combined_dataset %>% select(-GBD_TERM_NAME)

# Save the combined dataset to a CSV file
#write.csv(combined_dataset, "GBD_combined_dataset_EFO.csv", row.names = FALSE)


```


Obtain the GBD hierarchies to sum the attention scores of each GBD cause name under its corresponding parent cause.

```{r}
h <- read_xlsx("IHME_GBD_2021_A1_HIERARCHIES_Y2024M05D15.XLSX", sheet=3)

head(h)
```

```{r}

# keep only those under CMNN or NCD catagorise
h1 <- h[grep("^[AB]", h$`Cause Outline`), ]

# keep only those under level 3 and 4 
h1  <- h1 %>%
  filter(Level %in% c(3, 4))


```

```{r}

# Count the number of zeros in the total_attention_score column
num_zeros <- sum(combined_dataset$total_attention_score == 0)

# Print the number of zeros
cat("Number of zeros in total_attention_score:", num_zeros, "\n")

```

```{r}
# list of GBD traits that are the tips of branches (i.e. are not parents to any other traits)
h3 <- subset(h1, ! `Cause Name` %in% `Parent Name`)

#  Rename the columns for clarity 
combined_dataset <- combined_dataset %>%
  rename(GBD.term =`GBD term`)

# Perform the merge operation
merged_data <- merge(h3, combined_dataset[, c("GBD.term", "total_attention_score","nhits","weighted_n", "weighted_nhits","weighted_attention_score_impact_factor")], 
                    by.x = "Cause Name", by.y = "GBD.term", all.x = TRUE)


# select only the columns of interest
matched_data_h3 <- merged_data[, c("Cause Name", "total_attention_score", "nhits", "weighted_n", "weighted_nhits","weighted_attention_score_impact_factor" )]

# Identify matched cause names
matched_cause_names <- intersect(h3$`Cause Name`, combined_dataset$GBD.term)

# Identify unmatched GBD.term values
unmatched_dataset <- combined_dataset[combined_dataset$GBD.term %in% setdiff(combined_dataset$GBD.term, matched_cause_names), ]

# Match `GBD.term` in unmatched with `Parent Name` in h1 to get the relationship 
matched_data <- unmatched_dataset %>%
  left_join(h1, by = c("GBD.term" = "Parent Name"))

# Rename the columns for clarity in matched_data
matched_data <- matched_data %>%
  rename(Parent_Name = GBD.term, 
         parents_total_attention_score = total_attention_score,
         parents_nhits = nhits,
         parents_weighted_n = weighted_n,
         parents_weighted_nhits = weighted_nhits,
         parents_weighted_attention_score_impact_factor = weighted_attention_score_impact_factor)


# final_matched_data_attention to get the score of the child of that parents 
final_matched_data_attention <- merge(matched_data, combined_dataset, by.x = "Cause Name", by.y = "GBD.term", all.x = TRUE)

#  Select the necessary columns (keeping all Cause Names under each Parent Name)
final_matched_data_attention <- final_matched_data_attention %>%
  select(Parent_Name, total_attention_score, `Cause Name`, parents_total_attention_score,
         parents_weighted_attention_score_impact_factor,
         parents_weighted_nhits,
         weighted_nhits,
         weighted_attention_score_impact_factor, parents_nhits, nhits,
         parents_weighted_n, weighted_n)


# Sum up total_attention_score for each Parent_Name (within row)
final_data <- final_matched_data_attention %>%
  group_by(Parent_Name) %>%
  summarise(
    parents_total_attention_score = first(parents_total_attention_score),
    parents_weighted_attention_score_impact_factor = first(parents_weighted_attention_score_impact_factor),
    parents_weighted_nhits = first(parents_weighted_nhits),
    parents_nhits = first(parents_nhits),
    parents_weighted_n = first(parents_weighted_n),
    total_attention_score = sum(total_attention_score, na.rm = TRUE),
    weighted_nhits = sum(weighted_nhits, na.rm = TRUE),
    weighted_n = sum(weighted_n, na.rm = TRUE),
    nhits = sum(nhits, na.rm = TRUE),
    weighted_attention_score_impact_factor = sum(weighted_attention_score_impact_factor, na.rm = TRUE)
  )


# sum the results in one column
final_data <- final_data %>%
  mutate(
    final_total_attention_score = parents_total_attention_score + total_attention_score,
    final_weighted_attention_score_impact_factor = parents_weighted_attention_score_impact_factor + weighted_attention_score_impact_factor,
    final_total_weighted_nhits = parents_weighted_nhits + weighted_nhits, 
     final_total_weighted_n = weighted_n + parents_weighted_n, 
    final_nhits  = nhits + parents_nhits
  ) %>%
  select(Parent_Name, final_total_attention_score, final_weighted_attention_score_impact_factor, final_total_weighted_nhits, final_total_weighted_n,final_nhits )

#  Rename the columns to combine 
final_data <- final_data %>%
  rename(GBD.term = Parent_Name)

#  Rename the columns to combine 
matched_data_h3 <- matched_data_h3 %>%
  rename(
    GBD.term = `Cause Name`,
    h3_total_attention_score = total_attention_score,
    h3_weighted_nhits = weighted_nhits,
    h3_weighted_attention_score_impact_factor = weighted_attention_score_impact_factor,
    h3_weighted_n = weighted_n,
    h3_nhits = nhits
 )



#  Merge the two data frames on "GBD.term"
combined_data <- merge(final_data, matched_data_h3, by = "GBD.term", all = TRUE)

# Combined_data and merged dataframe
combined_data <- combined_data %>%
  mutate(
    total_attention_score = coalesce(final_total_attention_score, 0) + coalesce(h3_total_attention_score, 0),
    nhit = coalesce(final_nhits, 0) + coalesce(h3_nhits, 0),
    weighted_nhits = coalesce(final_total_weighted_nhits, 0) + coalesce(h3_weighted_nhits, 0),
    weighted_n = coalesce(final_total_weighted_n, 0) + coalesce(h3_weighted_n, 0),
    weighted_attention_score_impact_factor = coalesce(final_weighted_attention_score_impact_factor, 0) + coalesce(h3_weighted_attention_score_impact_factor, 0)
  ) %>%
  select(GBD.term, total_attention_score, weighted_nhits, weighted_attention_score_impact_factor, weighted_n, nhit)


# Count the number of zeros in the total_attention_score column
num_zeros <- sum(combined_data$total_attention_score == 0)

# Print the number of zeros
cat("Number of zeros in total_attention_score:", num_zeros, "\n")

# give the name back 
combined_dataset <- combined_data

#  Rename the columns to combine 
combined_dataset <- combined_dataset %>%
  rename(`GBD term`= GBD.term)

#write.csv(combined_data, file = "GBD_combined_dataset_EFO.csv", row.names = FALSE)

```



load the GBD DALY data, verify any missing values, and inspect the structure of the dataset
 
```{r}

# Load the GBD DALY data
gbd_daly_data <- read_csv('IHME-GBD_2021_DATA-120ebfcd-1.csv')

 
# Inspect the structure of the GBD DALY data
str(gbd_daly_data)




```

```{r}
# List of causes in level 0, 1 and 2 to exclude in Communicable Diseases, Non-Communicable Diseases, Injury and All Causes categories

exclude_causes <- c(
  "All causes", 
  "Communicable, maternal, neonatal, and nutritional diseases",
  "HIV/AIDS and sexually transmitted infections",
  "Respiratory infections and tuberculosis",
  "Enteric infections",
  "Neglected tropical diseases and malaria",
  "Other infectious diseases",
  "Maternal and neonatal disorders",
  "Nutritional deficiencies",
  "Non-communicable diseases",
  "Neoplasms",
  "Cardiovascular diseases",
  "Chronic respiratory diseases",
  "Digestive diseases",
  "Neurological disorders",
  "Mental disorders",
  "Substance use disorders",
  "Diabetes and kidney diseases",
  "Skin and subcutaneous diseases",
  "Sense organ diseases",
  "Musculoskeletal disorders",
  "Other non-communicable diseases",
  "Injuries",
  "Transport injuries",
  "Unintentional injuries",
  "Self-harm and interpersonal violence",
  "Other COVID-19 pandemic-related outcomes",
  "Total cancers",
  "Total burden related to hepatitis B",
  "Total burden related to hepatitis C",
  "Total burden related to Non-alcoholic fatty liver disease (NAFLD)",
  "Total Cancers excluding Non-melanoma skin cancer"
)

# Filter the dataset to exclude the specified causes
gbd_daly_data <- gbd_daly_data %>%
  filter(!cause_name %in% exclude_causes)

# Additional causes under injuries category to exclude (37)
additional_exclude_causes <- c(
  "Road injuries",
  "Pedestrian road injuries",
  "Cyclist road injuries",
  "Motorcyclist road injuries",
  "Motor vehicle road injuries",
  "Other road injuries",
  "Other transport injuries",
  "Falls",
  "Drowning",
  "Fire, heat, and hot substances",
  "Poisonings",
  "Poisoning by carbon monoxide",
  "Poisoning by other means",
  "Exposure to mechanical forces",
  "Unintentional firearm injuries",
  "Other exposure to mechanical forces",
  "Adverse effects of medical treatment",
  "Animal contact",
  "Venomous animal contact",
  "Non-venomous animal contact",
  "Foreign body",
  "Pulmonary aspiration and foreign body in airway",
  "Foreign body in eyes",
  "Foreign body in other body part",
  "Environmental heat and cold exposure",
  "Exposure to forces of nature",
  "Other unintentional injuries",
  "Self-harm",
  "Self-harm by firearm",
  "Self-harm by other specified means",
  "Interpersonal violence",
  "Physical violence by firearm",
  "Physical violence by sharp object",
  "Sexual violence",
  "Physical violence by other means",
  "Conflict and terrorism",
  "Police conflict and executions"
)

# Combine the original exclude list with the additional causes
exclude_causes <- c(exclude_causes, additional_exclude_causes)

# Filter the dataset to exclude the specified causes
gbd_daly_data <- gbd_daly_data %>%
  filter(!cause_name %in% exclude_causes)

```

Assessing the relationship between GWAS attention and global need, using an inequality measure.This will be done via filtering the data by Number of DALY and then merging by GBD term.

```{r}


#2021
gbd_daly_data <- gbd_daly_data %>%
  filter(metric_name == "Number") %>%
  rename(`GBD term`= cause_name, DALY = val)


# Merge the DALY values into the combined dataset
combined_dataset <- combined_dataset %>%
  left_join(gbd_daly_data, by = c("GBD term" = "GBD term"))


# Verify the merge
head(combined_dataset)


# Verify the data
summary(combined_dataset$total_attention_score)
summary(combined_dataset$DALY)

#write.csv(combined_dataset, "combined_dataset_EFOM.csv", row.names = FALSE)

```






Try to identify any difference or duplicates between combined dataset and the data set that we started with in the manual mapping (Duplicate check).  
 

```{r}
unmatched_gbd_terms <- anti_join(gbd_daly_data, combined_dataset, by = c("GBD term" = "GBD term"))

unmatched_gbd_terms <- unmatched_gbd_terms %>%
  distinct(`GBD term`, .keep_all = TRUE)

# Get the unique GBD terms in each dataset
combined_gbd_terms <- unique(combined_dataset$`GBD term`)
gbd_gbd_terms <- unique(gbd_daly_data$`GBD term`)

# Identify terms in combined_dataset not in gbd_daly_data
terms_only_in_combined <- setdiff(combined_gbd_terms, gbd_gbd_terms)

# Identify terms in gbd_daly_data not in combined_dataset
terms_only_in_gbd_daly <- setdiff(gbd_gbd_terms, combined_gbd_terms)

# Get the lengths of the unique terms
len_combined <- length(terms_only_in_combined)
len_gbd_daly <- length(terms_only_in_gbd_daly)

# Determine the maximum length to ensure both columns in the data frame have the same number of rows
max_length <- max(len_combined, len_gbd_daly)

# Combine the differences into a data frame for better visualization
diff_2 <- data.frame(
  Terms_Only_in_Combined_Dataset = c(terms_only_in_combined, rep(NA, max_length - len_combined)),
  Terms_Only_in_GBD_Daly_Dataset = c(terms_only_in_gbd_daly, rep(NA, max_length - len_gbd_daly))
)

# the differences
(diff_2)

#write.csv(diff_2, "diff_2.csv", row.names = FALSE)
#write.csv(combined_dataset, "combined_dataset_EFO.csv", row.names = FALSE)


```



Split the dataset into three categories: overall GBD terms, NCD (non-communicable diseases), and CMNN (communicable, maternal, neonatal, and nutritional diseases).

```{r}

broader_categories_dataset <- read_xlsx("IHME_GBD_2021_A1_HIERARCHIES_Y2024M05D15.XLSX", sheet=3)

 
head(broader_categories_dataset)
```

```{r}

#  Rename the columns to merge 
combined_dataset <- combined_dataset %>%
  rename("Cause Name" = `GBD term`)

merged_dataset <- merge(combined_dataset, broader_categories_dataset, by = "Cause Name", all.x = TRUE)
```

based on the GBD, here we should have 87 * 28 locations for the Communicable, maternal, neonatal, and nutritional diseases

```{r}
merged_dataset_EFO_CMNN <- merged_dataset %>%
  filter(substr(`Cause Outline`, 1, 1) %in% c("A"))

#write.csv(merged_dataset_EFO_CMNN, "GBD_merged_dataset_EFO_CMNN.csv", row.names = FALSE)
```

based on the GBD, here we should have 221 * 28 for Non-communicable diseases diseases
```{r}
merged_dataset_EFO_NC <- merged_dataset %>%
  filter(substr(`Cause Outline`, 1, 1) %in% c("B"))

#write.csv(merged_dataset_EFO_NC, "GBD_merged_dataset_EFO_NC.csv", row.names = FALSE)
```

based on the GBD, here we should have 308 * 28 locations for merged_dataset_EFO_exclude_Injuries

```{r}
merged_dataset_EFO_exclude_Injuries <- combined_dataset

#write.csv(merged_dataset_EFO_exclude_Injuries, "EFO_merged_dataset_exclude_Injuries.csv", row.names = FALSE)


```

