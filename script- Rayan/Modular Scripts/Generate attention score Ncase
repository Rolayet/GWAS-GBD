#######################################################
### Generate GWAS attention scores from GWAS Catalog using ncase = Initial_Sample_Cases + Replication_Sample_Cases ###
#######################################################
	
## Read the GWAS Catalog data and Load necessary libraries
library(dplyr)
library(data.table)
library(tidyr)
library(stringr)
library(DescTools)
library(ggplot2)
library(stats)
library(readr)
library(ontologyIndex)
library(readxl)
library(openxlsx)
library(boot)
library(LorenzRegression)

a <- read_xlsx("gwas_catalog_v1.0.2.1-studies_r2024-06-07.xlsx")




## Step 1: Develop the attention score using the sample size (ncase = Initial_Sample_Cases + Replication_Sample_Cases).

fn <- function(x) {
    # Handle NA values
    if (is.na(x)) return(0)
    
    # Remove commas from numbers
    b <- gsub("(\\d),(?=\\d)", "\\1", x, perl = TRUE) %>%
        # Split sample components based on ','
        strsplit(", ") %>%
        unlist()
    
    # Keep components that contain the word 'cases'
    b1 <- grep("cases", b, value = TRUE)
    
    # If none, probably a continuous trait
    if (length(b1) == 0) {
        b1 <- b
    }
    
    # Now just extract the numbers from each 'cases' sample component and sum them
    result <- suppressWarnings({
        b1 %>%
            sapply(function(y) {
                num <- strsplit(y, " ") %>%
                       unlist() %>% 
                       as.numeric() %>% 
                       na.omit() %>% 
                       first()
                if (length(num) == 0) return(0)
                return(num)
            }) %>% sum(na.rm = TRUE)
    })
    
    # Ensure the result is numeric
    if (is.na(result)) return(0)
    return(result)
}

# Apply the function to the data frame
a <- a %>%
    mutate(
        Initial_Sample_Cases = sapply(`INITIAL SAMPLE SIZE`, fn),
        Replication_Sample_Cases = sapply(`REPLICATION SAMPLE SIZE`, fn)
    )

# Create a new column 'Total_Sample_Cases' by summing the two columns row-wise
a <- a %>%
    mutate(ncase = Initial_Sample_Cases + Replication_Sample_Cases)

# View the resulting data frame
head(a)







## Have a look at the data

hist(a$`ASSOCIATION COUNT`, breaks=100)


## Sometimes there is more than one EFO term (comma separated). Split them into separate lines

head(a, 10)
a <- a %>%
    tidyr::separate_rows(MAPPED_TRAIT_URI, sep = ", ")
head(a, 10)




## Summarize total cases (ncase) by MAPPED_TRAIT_URI

-DISEASE_TRAIT values are grouped, as this column will be used in the second stage to find matches using string functions.

-PUBMEDID values are grouped and later expanded into separate rows to ensure each publication ID is represented individually.


#  Group by MAPPED_TRAIT_URI, then summarize
attention <- a %>%
  group_by(MAPPED_TRAIT_URI) %>%
  summarise(
    total_ncase = sum(ncase, na.rm = TRUE),
    DISEASE_TRAIT = paste(unique(`DISEASE/TRAIT`), collapse = "; "),
    PUBMEDID = paste(unique(PUBMEDID), collapse = ", "),
    .groups = 'drop'
  )

# Expand PUBMEDID into separate rows
attention <- attention %>%
  separate_rows(PUBMEDID, sep = ", ") 


# check the result
str(attention)
